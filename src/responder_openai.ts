// Responds using the embeddings generated by openai's assistants api

import OpenAI from "openai";
import * as dotenv from "dotenv";
dotenv.config();
import { MessageContentText } from "openai/resources/beta/threads/index.mjs";
import { questions } from "./questions.js";

const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });

async function main() {
  const assistantId = process.env.OPENAI_ASSISTANT_ID;
  const thread = await openai.beta.threads.create();

  for (const question of questions) {
    await openai.beta.threads.messages.create(thread.id, {
      role: "user",
      content: question,
    });

    const run = await openai.beta.threads.runs.create(thread.id, {
      assistant_id: assistantId,
      instructions: `Be as concise as possible in your responses. 
      Convert LaTeX to unformatted text: convert "( \Omicron(\lg n) )" to "O(log n)". Always try
      to respond using information from the knowledge base. If the question isn't about data structures,
      reply with "I don't assist with anything unrelated to data structures". Limit your responses to 20 tokens.
      Don't include sources in your response. When asked for specific answer, give the answer first and then an explanation.`,
    });

    // Currently, openai wants us to retrieve the status repeatedly until the run is 'completed'
    let runStatus = (await openai.beta.threads.runs.retrieve(thread.id, run.id))
      .status;
    while (runStatus !== "completed") {
      await new Promise((resolve) => setTimeout(resolve, 500));
      runStatus = (await openai.beta.threads.runs.retrieve(thread.id, run.id))
        .status;
    }

    const messagesInThread = await openai.beta.threads.messages.list(thread.id);
    const responseTextObject = messagesInThread.data[0]
      .content[0] as MessageContentText;

    console.log(`Question: ${question}`);
    console.log(`Answer: ${responseTextObject.text.value}\n`);
  }
}
main();
